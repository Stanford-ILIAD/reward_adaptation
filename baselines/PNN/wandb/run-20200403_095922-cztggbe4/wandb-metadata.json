{
    "root": "/iliad/u/caozj/reward_adaptation",
    "program": "train.py",
    "git": {
        "remote": "https://github.com/Stanford-ILIAD/reward_adaptation.git",
        "commit": "127eac8b5b15bc4d1d537a3f6c208bf38fff03fc"
    },
    "email": "caozhangjie14@gmail.com",
    "startedAt": "2020-04-03T09:59:22.382732",
    "host": "iliad2.stanford.edu",
    "username": "caozj",
    "executable": "/iliad/u/caozj/anaconda3/envs/reward/bin/python",
    "os": "Linux-4.4.0-142-generic-x86_64-with-debian-stretch-sid",
    "python": "3.6.10",
    "cpu_count": 32,
    "args": [
        "--experiment_dir",
        "output/gridworld_continuous",
        "--experiment_name",
        "MO_RR2LR_ppn",
        "--source_env",
        "RR",
        "--target_env",
        "ContinuousMultiObjLR-v0"
    ],
    "state": "killed",
    "jobType": null,
    "mode": "run",
    "project": "continuous",
    "heartbeatAt": "2020-04-03T09:59:29.845118",
    "exitcode": 255
}
