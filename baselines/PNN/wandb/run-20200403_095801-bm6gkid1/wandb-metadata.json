{
    "root": "/iliad/u/caozj/reward_adaptation",
    "program": "train.py",
    "git": {
        "remote": "https://github.com/Stanford-ILIAD/reward_adaptation.git",
        "commit": "127eac8b5b15bc4d1d537a3f6c208bf38fff03fc"
    },
    "email": "caozhangjie14@gmail.com",
    "startedAt": "2020-04-03T09:58:01.389462",
    "host": "iliad2.stanford.edu",
    "username": "caozj",
    "executable": "/iliad/u/caozj/anaconda3/envs/reward/bin/python",
    "os": "Linux-4.4.0-142-generic-x86_64-with-debian-stretch-sid",
    "python": "3.6.10",
    "cpu_count": 32,
    "args": [
        "--experiment_dir",
        "output/gridworld_continuous",
        "--experiment_name",
        "MO_LL2RL_ppn",
        "--source_env",
        "LL",
        "--target_env",
        "ContinuousMultiObjRL-v0"
    ],
    "state": "finished",
    "jobType": null,
    "mode": "run",
    "project": "continuous",
    "heartbeatAt": "2020-04-03T10:05:47.355101",
    "exitcode": 0
}
